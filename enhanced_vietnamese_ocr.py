#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c nh·∫≠n di·ªán d·∫•u ti·∫øng Vi·ªát cho PaddleOCR
Bao g·ªìm preprocessing, post-processing v√† fine-tuning parameters
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
from paddleocr import PaddleOCR
import unicodedata
import re
import logging
from typing import Dict, List, Any, Tuple
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VietnameseOCREnhancer:
    def __init__(self):
        """Kh·ªüi t·∫°o OCR v·ªõi c·∫•u h√¨nh t·ªëi ∆∞u cho ti·∫øng Vi·ªát"""
        self.ocr_configs = {
            # C·∫•u h√¨nh ch√≠nh
            'primary': PaddleOCR(
                use_angle_cls=True, 
                lang='vi', 
                use_gpu=False, 
                show_log=False,
                det_limit_side_len=960,
                det_limit_type='max',
                rec_batch_num=6
            ),
            # C·∫•u h√¨nh cao c·∫•p h∆°n
            'enhanced': PaddleOCR(
                use_angle_cls=True, 
                lang='vi', 
                use_gpu=False, 
                show_log=False,
                det_limit_side_len=1280,
                det_limit_type='max',
                rec_batch_num=1,
                det_db_thresh=0.3,
                det_db_box_thresh=0.5
            )
        }
        
        # Dictionary √°nh x·∫° c√°c k√Ω t·ª± b·ªã nh·∫≠n di·ªán sai
        self.vietnamese_char_mapping = {
            # C√°c l·ªói th∆∞·ªùng g·∫∑p v·ªõi PaddleOCR
            'D√∂c': 'ƒê·ªôc',
            'Tudo': 'T·ª± do', 
            'Hanh ph√ºc': 'H·∫°nh ph√∫c',
            'phuc': 'ph√∫c',
            'd√∂c': 'ƒë·ªôc',
            'tudo': 't·ª± do',
            'hanh': 'h·∫°nh',
            'ph√ºc': 'ph√∫c',
            'lap': 'l·∫≠p',
            # Th√™m c√°c mapping kh√°c
            'a': '√°',  # context-dependent
            'e': '·ªÉ',  # context-dependent  
            'o': '·ªì',  # context-dependent
            'u': '∆∞',  # context-dependent
            'i': '·ªã',  # context-dependent
            # Mapping v·ªõi diacritics
            '√∂': '·ªì',
            '√º': '∆∞',
            '√§': 'ƒÉ',
            '√™': '·ªÅ',
        }
        
        # T·ª´ ƒëi·ªÉn ti·∫øng Vi·ªát ph·ªï bi·∫øn
        self.vietnamese_words = {
            'ƒë·ªôc l·∫≠p', 't·ª± do', 'h·∫°nh ph√∫c', 'vi·ªát nam', 'h·ªì ch√≠ minh',
            'th√†nh ph·ªë', 'qu·∫≠n', 'ph∆∞·ªùng', 'ƒë∆∞·ªùng', 's·ªë nh√†',
            'ƒëi·ªán tho·∫°i', 'email', 'website', 'c√¥ng ty', 'doanh nghi·ªáp'
        }

    def preprocess_image(self, image_path: str, method: str = 'enhanced') -> str:
        """Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ c·∫£i thi·ªán OCR"""
        try:
            # ƒê·ªçc ·∫£nh
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}")
            
            # Convert to PIL
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            
            if method == 'enhanced':
                # C·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n
                enhancer = ImageEnhance.Contrast(pil_image)
                pil_image = enhancer.enhance(1.5)
                
                # C·∫£i thi·ªán ƒë·ªô s·∫Øc n√©t
                enhancer = ImageEnhance.Sharpness(pil_image)
                pil_image = enhancer.enhance(1.2)
                
                # Resize n·∫øu ·∫£nh qu√° nh·ªè
                width, height = pil_image.size
                if width < 800 or height < 600:
                    scale = max(800/width, 600/height)
                    new_size = (int(width * scale), int(height * scale))
                    pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
            
            elif method == 'grayscale_enhanced':
                # Convert to grayscale
                pil_image = pil_image.convert('L')
                
                # Convert back to numpy
                np_image = np.array(pil_image)
                
                # Apply adaptive threshold
                np_image = cv2.adaptiveThreshold(
                    np_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                    cv2.THRESH_BINARY, 11, 2
                )
                
                # Convert back to PIL
                pil_image = Image.fromarray(np_image)
            
            # L∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω
            temp_path = image_path.replace('.', '_processed.')
            pil_image.save(temp_path)
            return temp_path
            
        except Exception as e:
            logger.error(f"L·ªói preprocessing: {e}")
            return image_path

    def postprocess_text(self, text: str) -> str:
        """H·∫≠u x·ª≠ l√Ω vƒÉn b·∫£n ƒë·ªÉ s·ª≠a l·ªói d·∫•u ti·∫øng Vi·ªát"""
        if not text:
            return text
        
        # √Åp d·ª•ng character mapping
        processed_text = text
        for wrong, correct in self.vietnamese_char_mapping.items():
            processed_text = processed_text.replace(wrong, correct)
        
        # Regex patterns ƒë·ªÉ s·ª≠a m·ªôt s·ªë l·ªói ph·ªï bi·∫øn
        patterns = [
            (r'D√∂c\s+lap', 'ƒê·ªôc l·∫≠p'),
            (r'Tudo', 'T·ª± do'),
            (r'Hanh\s+ph√ºc', 'H·∫°nh ph√∫c'),
            (r'ph√ºc', 'ph√∫c'),
            (r'd√∂c', 'ƒë·ªôc'),
            (r'tudo', 't·ª± do'),
            (r'hanh', 'h·∫°nh'),
        ]
        
        for pattern, replacement in patterns:
            processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)
        
        return processed_text

    def enhanced_ocr(self, image_path: str, config: str = 'primary') -> Dict[str, Any]:
        """OCR v·ªõi c√°c c·∫£i ti·∫øn cho ti·∫øng Vi·ªát"""
        try:
            start_time = time.time()
            
            # Preprocessing
            processed_image_path = self.preprocess_image(image_path, 'enhanced')
            
            # OCR v·ªõi config ƒë∆∞·ª£c ch·ªçn
            ocr_engine = self.ocr_configs[config]
            result = ocr_engine.ocr(processed_image_path, cls=True)
            
            # X·ª≠ l√Ω k·∫øt qu·∫£
            texts = []
            confidences = []
            bboxes = []
            all_text = ""
            
            if result and len(result) > 0 and result[0]:
                for line in result[0]:
                    if line and len(line) >= 2:
                        bbox = line[0]
                        text_info = line[1]
                        if isinstance(text_info, (list, tuple)) and len(text_info) >= 2:
                            raw_text = text_info[0]
                            confidence = text_info[1]
                            
                            # Post-process text
                            processed_text = self.postprocess_text(raw_text)
                            
                            texts.append(processed_text)
                            confidences.append(confidence)
                            bboxes.append(bbox)
                            all_text += processed_text + " "
            
            # Cleanup temp file
            if processed_image_path != image_path and os.path.exists(processed_image_path):
                os.remove(processed_image_path)
            
            processing_time = time.time() - start_time
            
            return {
                "engine": f"Enhanced PaddleOCR ({config})",
                "text": all_text.strip(),
                "texts": texts,
                "confidences": confidences,
                "avg_confidence": sum(confidences) / len(confidences) if confidences else 0,
                "bboxes": bboxes,
                "processing_time": processing_time,
                "total_segments": len(texts)
            }
            
        except Exception as e:
            logger.error(f"L·ªói enhanced OCR: {e}")
            return {"error": str(e)}

    def test_multiple_configs(self, image_path: str) -> Dict[str, Any]:
        """Test v·ªõi nhi·ªÅu c·∫•u h√¨nh kh√°c nhau"""
        results = {}
        
        for config_name in self.ocr_configs.keys():
            logger.info(f"Testing v·ªõi config: {config_name}")
            result = self.enhanced_ocr(image_path, config_name)
            results[config_name] = result
        
        # So s√°nh k·∫øt qu·∫£
        best_config = self.find_best_config(results)
        
        return {
            "results": results,
            "best_config": best_config,
            "comparison": self.compare_configs(results)
        }

    def find_best_config(self, results: Dict[str, Any]) -> str:
        """T√¨m config t·ªët nh·∫•t d·ª±a tr√™n confidence v√† s·ªë k√Ω t·ª± ti·∫øng Vi·ªát"""
        best_score = 0
        best_config = "primary"
        
        vietnamese_chars = "√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë"
        vietnamese_chars += vietnamese_chars.upper()
        
        for config, result in results.items():
            if "error" not in result:
                confidence = result.get("avg_confidence", 0)
                text = result.get("text", "")
                vietnamese_count = sum(1 for char in text if char in vietnamese_chars)
                
                # Score = confidence * 0.7 + vietnamese_ratio * 0.3
                vietnamese_ratio = vietnamese_count / len(text) if text else 0
                score = confidence * 0.7 + vietnamese_ratio * 0.3
                
                if score > best_score:
                    best_score = score
                    best_config = config
        
        return best_config

    def compare_configs(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """So s√°nh c√°c config"""
        comparison = {}
        
        vietnamese_chars = "√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë"
        vietnamese_chars += vietnamese_chars.upper()
        
        for config, result in results.items():
            if "error" not in result:
                text = result.get("text", "")
                comparison[config] = {
                    "confidence": result.get("avg_confidence", 0),
                    "processing_time": result.get("processing_time", 0),
                    "text_length": len(text),
                    "vietnamese_chars": sum(1 for char in text if char in vietnamese_chars),
                    "segments": result.get("total_segments", 0)
                }
        
        return comparison

def main():
    """Test script"""
    print("üöÄ Testing Enhanced Vietnamese OCR...")
    
    enhancer = VietnameseOCREnhancer()
    
    # Test image
    test_image = "/Users/lechaukha12/Desktop/ocr-service/IMG_4620.png"
    
    if not os.path.exists(test_image):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {test_image}")
        return
    
    # Test v·ªõi multiple configs
    results = enhancer.test_multiple_configs(test_image)
    
    # In k·∫øt qu·∫£
    print("\nüìä K·∫æT QU·∫¢ TEST:")
    print(f"Best config: {results['best_config']}")
    
    for config, result in results['results'].items():
        if "error" not in result:
            print(f"\nüîß Config: {config}")
            print(f"  Text: {result['text'][:100]}...")
            print(f"  Confidence: {result['avg_confidence']:.2f}")
            print(f"  Processing time: {result['processing_time']:.2f}s")
            print(f"  Segments: {result['total_segments']}")
    
    print(f"\nüìà COMPARISON:")
    for config, stats in results['comparison'].items():
        print(f"  {config}:")
        print(f"    Vietnamese chars: {stats['vietnamese_chars']}")
        print(f"    Confidence: {stats['confidence']:.2f}")
        print(f"    Processing time: {stats['processing_time']:.2f}s")

if __name__ == "__main__":
    main()
